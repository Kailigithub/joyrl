general_cfg:
  version: 0.5.2
  algo_name: PPO
  env_name: gym
  device: cuda
  mode: train
  load_checkpoint: false
  load_path: Train_ALE/Pong-v5_PPO_20240122-213334 # if load checkpoint, then config path in 'tasks' dir
  load_model_step: best
  n_interactors: 1
  max_episode: -1
  max_step: 500
  seed: 1
  online_eval: true
  online_eval_episode: 10
  model_save_fre: 10
algo_cfg:
  ppo_type: clip
  independ_actor: true
  share_optimizer: false
  actor_branch_layers:
    - name: feature_1
      layers:
        - layer_type: conv2d
          in_channel: 4
          out_channel: 16
          kernel_size: 4
          stride: 2
          activation: relu
        - layer_type: pooling
          pooling_type: max2d
          kernel_size: 2
          stride: 2
          padding: 0
        - layer_type: conv2d
          in_channel: 16
          out_channel: 32
          kernel_size: 4
          stride: 2
          activation: relu
        - layer_type: pooling
          pooling_type: avg2d
          kernel_size: 2
          stride: 2
          padding: 0
        - layer_type: flatten
        - layer_type: norm
          norm_type: LayerNorm
          normalized_shape: 512
        - layer_type: linear
          layer_size: [128]
          activation: relu
  critic_branch_layers:
    - name: feature_1
      layers:
        - layer_type: conv2d
          in_channel: 4
          out_channel: 16
          kernel_size: 4
          stride: 2
          activation: relu
        - layer_type: pooling
          pooling_type: max2d
          kernel_size: 2
          stride: 2
          padding: 0
        - layer_type: conv2d
          in_channel: 16
          out_channel: 32
          kernel_size: 4
          stride: 2
          activation: relu
        - layer_type: pooling
          pooling_type: avg2d
          kernel_size: 2
          stride: 2
          padding: 0
        - layer_type: flatten
        - layer_type: norm
          norm_type: LayerNorm
          normalized_shape: 512
        - layer_type: linear
          layer_size: [128]
          activation: relu
  buffer_type: ONPOLICY_QUE
  actor_lr: 0.0003
  critic_lr: 0.001
  entropy_coef: 0.01
  eps_clip: 0.2
  gamma: 0.99
  k_epochs: 4
  batch_size: 256
  sgd_batch_size: 256
env_cfg:
  id: ALE/AirRaid-v5
  render_mode: null
  wrappers:
    - wrapper_name: SkipFrame
      skip: 2
    - wrapper_name: GrayScaleObservation
    - wrapper_name: ResizeObservation
      shape: 84
    - wrapper_name: FrameStack
      num_stack: 4
